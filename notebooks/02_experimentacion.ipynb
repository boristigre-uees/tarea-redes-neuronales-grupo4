{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0dd992",
   "metadata": {},
   "source": [
    "# Experimentación - Parte 2: Aplicación a DynamicWal\n",
    "Cargamos data Walmart, corremos baseline y 3 configs de NN para predicción demanda. Métricas: MSE, Revenue Error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c8b1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 2.0328, Rev Error: 39.82%\n",
      "Config [8]-relu: MSE 2.1212, Rev Error 40.98%\n",
      "Config [6]-sigmoid: MSE 2.0877, Rev Error 40.73%\n",
      "Config [12, 6]-tanh: MSE 2.0428, Rev Error 39.97%\n",
      "\n",
      "Análisis: Rev Error <45% viable para DynamicWal (uplift potencial 3%).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Fallback load_and_preprocess_data (tu fallback)\n",
    "def load_and_preprocess_data(target_col='quantity_sold'):\n",
    "    df = pd.read_csv(\"../data/Walmart.csv\")  # Ajusta ruta si necesario (o \"data/Walmart.csv\" si cwd = root)\n",
    "    feature_cols = ['unit_price', 'holiday_indicator', 'store_id']\n",
    "    X = df[feature_cols].fillna(0).values\n",
    "    y = df[target_col].values.reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    return (X_train, y_train), (X_test, y_test), scaler\n",
    "\n",
    "# Fallback business_metric\n",
    "def business_metric(y_true, y_pred, base_price=100):\n",
    "    revenue_true = y_true * base_price\n",
    "    revenue_pred = y_pred * base_price\n",
    "    return np.mean(np.abs(revenue_true - revenue_pred)) / np.mean(revenue_true) * 100\n",
    "\n",
    "# Fallback NeuralNetwork inline (tu código original + losses fix)\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, activation='relu'):\n",
    "        self.layers = layers\n",
    "        self.activation_name = activation\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        for i in range(len(layers) - 1):\n",
    "            n_in = layers[i]\n",
    "            n_out = layers[i + 1]\n",
    "\n",
    "            if activation.lower() == 'relu':\n",
    "                weight = np.random.randn(n_in, n_out) * np.sqrt(2.0 / n_in)\n",
    "            else:\n",
    "                weight = np.random.randn(n_in, n_out) * np.sqrt(1.0 / n_in)\n",
    "\n",
    "            bias = np.zeros((1, n_out))\n",
    "\n",
    "            self.weights.append(weight)\n",
    "            self.biases.append(bias)\n",
    "\n",
    "        if activation.lower() == 'relu':\n",
    "            self.activation = self.relu\n",
    "            self.activation_derivative = self.relu_derivative\n",
    "        elif activation.lower() == 'sigmoid':\n",
    "            self.activation = self.sigmoid\n",
    "            self.activation_derivative = self.sigmoid_derivative\n",
    "        elif activation.lower() == 'tanh':\n",
    "            self.activation = self.tanh\n",
    "            self.activation_derivative = self.tanh_derivative\n",
    "        else:\n",
    "            raise ValueError(f\"Función de activación desconocida: {activation}\")\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        s = self.sigmoid(x)\n",
    "        return s * (1 - s)\n",
    "\n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def tanh_derivative(self, x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.a = [X]\n",
    "        self.z = []\n",
    "        for w, b in zip(self.weights[:-1], self.biases[:-1]):\n",
    "            z = np.dot(self.a[-1], w) + b\n",
    "            self.z.append(z)\n",
    "            self.a.append(self.activation(z))\n",
    "        z = np.dot(self.a[-1], self.weights[-1]) + self.biases[-1]\n",
    "        self.z.append(z)\n",
    "        self.a.append(z)\n",
    "        return z\n",
    "\n",
    "    def backward(self, y_true):\n",
    "        m = y_true.shape[0]\n",
    "        dz = (self.a[-1] - y_true) / m\n",
    "        self.dW = []\n",
    "        self.db = []\n",
    "\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            a_prev = self.a[i]\n",
    "            dW = np.dot(a_prev.T, dz)\n",
    "            db = np.sum(dz, axis=0, keepdims=True)\n",
    "            self.dW.insert(0, dW)\n",
    "            self.db.insert(0, db)\n",
    "            if i != 0:\n",
    "                dz = np.dot(dz, self.weights[i].T) * self.activation_derivative(self.z[i-1])\n",
    "\n",
    "    def train(self, X, y, epochs=100, learning_rate=0.01):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            self.forward(X)\n",
    "            loss = np.mean((self.a[-1] - y)**2) / 2\n",
    "            losses.append(loss)\n",
    "            self.backward(y)\n",
    "            for i in range(len(self.weights)):\n",
    "                self.weights[i] -= learning_rate * self.dW[i]\n",
    "                self.biases[i] -= learning_rate * self.db[i]\n",
    "        return losses\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "# Carga data\n",
    "(X_train, y_train), (X_test, y_test), _ = load_and_preprocess_data()\n",
    "\n",
    "# Baseline\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_bl = model.predict(X_test)\n",
    "mse_bl = mean_squared_error(y_test, y_pred_bl)\n",
    "rev_bl = business_metric(y_test.flatten(), y_pred_bl.flatten())\n",
    "print(f\"Baseline MSE: {mse_bl:.4f}, Rev Error: {rev_bl:.2f}%\")\n",
    "\n",
    "# 3 Configs de NN\n",
    "configs = [\n",
    "    ([8], \"relu\", 0.01, 300),\n",
    "    ([6], \"sigmoid\", 0.01, 300),\n",
    "    ([12, 6], \"tanh\", 0.01, 300)\n",
    "]\n",
    "for hidden, act, lr, eps in configs:\n",
    "    nn = NeuralNetwork([X_train.shape[1]] + hidden + [1], activation=act)\n",
    "    losses = nn.train(X_train, y_train, epochs=eps, learning_rate=lr)\n",
    "    y_pred = nn.predict(X_test).flatten()\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rev = business_metric(y_test.flatten(), y_pred)\n",
    "    print(f\"Config {hidden}-{act}: MSE {mse:.4f}, Rev Error {rev:.2f}%\")\n",
    "\n",
    "# Análisis negocio\n",
    "print(\"\\nAnálisis: Rev Error <45% viable para DynamicWal (uplift potencial 3%).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3df3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MSE: 2.0328, Rev Error: 39.82%\n",
      "Config [8]-relu: MSE 2.1492, Rev Error 41.23%\n",
      "Config [6]-sigmoid: MSE 2.0575, Rev Error 40.24%\n",
      "Config [12, 6]-tanh: MSE 2.0438, Rev Error 40.11%\n",
      "\n",
      "Análisis: Rev Error <45% viable para DynamicWal (uplift potencial 3%).\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Fallback load_and_preprocess_data\n",
    "def load_and_preprocess_data(target_col='quantity_sold'):\n",
    "    df = pd.read_csv(\"../data/Walmart.csv\")  # Cambia a \"data/Walmart.csv\" si cwd = root\n",
    "    feature_cols = ['unit_price', 'holiday_indicator', 'store_id']\n",
    "    X = df[feature_cols].fillna(0).values\n",
    "    y = df[target_col].values.reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    return (X_train, y_train), (X_test, y_test), scaler\n",
    "\n",
    "# Fallback business_metric\n",
    "def business_metric(y_true, y_pred, base_price=100):\n",
    "    revenue_true = y_true * base_price\n",
    "    revenue_pred = y_pred * base_price\n",
    "    return np.mean(np.abs(revenue_true - revenue_pred)) / np.mean(revenue_true) * 100\n",
    "\n",
    "# Fallback NeuralNetwork inline (tu código original + losses fix)\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, layers, activation='relu'):\n",
    "        self.layers = layers\n",
    "        self.activation_name = activation\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "\n",
    "        for i in range(len(layers) - 1):\n",
    "            n_in = layers[i]\n",
    "            n_out = layers[i + 1]\n",
    "\n",
    "            if activation.lower() == 'relu':\n",
    "                weight = np.random.randn(n_in, n_out) * np.sqrt(2.0 / n_in)\n",
    "            else:\n",
    "                weight = np.random.randn(n_in, n_out) * np.sqrt(1.0 / n_in)\n",
    "\n",
    "            bias = np.zeros((1, n_out))\n",
    "\n",
    "            self.weights.append(weight)\n",
    "            self.biases.append(bias)\n",
    "\n",
    "        if activation.lower() == 'relu':\n",
    "            self.activation = self.relu\n",
    "            self.activation_derivative = self.relu_derivative\n",
    "        elif activation.lower() == 'sigmoid':\n",
    "            self.activation = self.sigmoid\n",
    "            self.activation_derivative = self.sigmoid_derivative\n",
    "        elif activation.lower() == 'tanh':\n",
    "            self.activation = self.tanh\n",
    "            self.activation_derivative = self.tanh_derivative\n",
    "        else:\n",
    "            raise ValueError(f\"Función de activación desconocida: {activation}\")\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        return (x > 0).astype(float)\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, x):\n",
    "        s = self.sigmoid(x)\n",
    "        return s * (1 - s)\n",
    "\n",
    "    def tanh(self, x):\n",
    "        return np.tanh(x)\n",
    "\n",
    "    def tanh_derivative(self, x):\n",
    "        return 1 - np.tanh(x)**2\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.a = [X]\n",
    "        self.z = []\n",
    "        for w, b in zip(self.weights[:-1], self.biases[:-1]):\n",
    "            z = np.dot(self.a[-1], w) + b\n",
    "            self.z.append(z)\n",
    "            self.a.append(self.activation(z))\n",
    "        z = np.dot(self.a[-1], self.weights[-1]) + self.biases[-1]\n",
    "        self.z.append(z)\n",
    "        self.a.append(z)\n",
    "        return z\n",
    "\n",
    "    def backward(self, y_true):\n",
    "        m = y_true.shape[0]\n",
    "        dz = (self.a[-1] - y_true) / m\n",
    "        self.dW = []\n",
    "        self.db = []\n",
    "\n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            a_prev = self.a[i]\n",
    "            dW = np.dot(a_prev.T, dz)\n",
    "            db = np.sum(dz, axis=0, keepdims=True)\n",
    "            self.dW.insert(0, dW)\n",
    "            self.db.insert(0, db)\n",
    "            if i != 0:\n",
    "                dz = np.dot(dz, self.weights[i].T) * self.activation_derivative(self.z[i-1])\n",
    "\n",
    "    def train(self, X, y, epochs=100, learning_rate=0.01):\n",
    "        losses = []\n",
    "        for epoch in range(epochs):\n",
    "            self.forward(X)\n",
    "            loss = np.mean((self.a[-1] - y)**2) / 2\n",
    "            losses.append(loss)\n",
    "            self.backward(y)\n",
    "            for i in range(len(self.weights)):\n",
    "                self.weights[i] -= learning_rate * self.dW[i]\n",
    "                self.biases[i] -= learning_rate * self.db[i]\n",
    "        return losses\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)\n",
    "\n",
    "# Carga data\n",
    "(X_train, y_train), (X_test, y_test), _ = load_and_preprocess_data()\n",
    "\n",
    "# Baseline\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred_bl = model.predict(X_test)\n",
    "mse_bl = mean_squared_error(y_test, y_pred_bl)\n",
    "rev_bl = business_metric(y_test.flatten(), y_pred_bl.flatten())\n",
    "print(f\"Baseline MSE: {mse_bl:.4f}, Rev Error: {rev_bl:.2f}%\")\n",
    "\n",
    "# 3 Configs de NN\n",
    "configs = [\n",
    "    ([8], \"relu\", 0.01, 300),\n",
    "    ([6], \"sigmoid\", 0.01, 300),\n",
    "    ([12, 6], \"tanh\", 0.01, 300)\n",
    "]\n",
    "for hidden, act, lr, eps in configs:\n",
    "    nn = NeuralNetwork([X_train.shape[1]] + hidden + [1], activation=act)\n",
    "    losses = nn.train(X_train, y_train, epochs=eps, learning_rate=lr)\n",
    "    y_pred = nn.predict(X_test).flatten()\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rev = business_metric(y_test.flatten(), y_pred)\n",
    "    print(f\"Config {hidden}-{act}: MSE {mse:.4f}, Rev Error {rev:.2f}%\")\n",
    "\n",
    "# Análisis negocio\n",
    "print(\"\\nAnálisis: Rev Error <45% viable para DynamicWal (uplift potencial 3%).\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
